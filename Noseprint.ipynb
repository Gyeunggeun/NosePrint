{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 강아지를 비문으로 인식할 수 있는 다중 분류 딥러닝 모델\n",
    "# 패키지 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import cv2, os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.backend import clear_session\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist, fashion_mnist\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # json 파일 불러오기\n",
    "# import os\n",
    "#\n",
    "# json_files = []\n",
    "#\n",
    "# for i in range(1, 25):\n",
    "#     if i not in [21, 23]:\n",
    "#         json_file = f\"D:\\\\Dog\\\\noseprints\\\\data\\\\a{i:03d}.json\"\n",
    "#         json_files.append(json_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "#\n",
    "# # JSON 파일 범위 지정\n",
    "# json_range = list(range(1, 25))\n",
    "# json_range.remove(21)  # a021.json 제외\n",
    "# json_range.remove(23)  # a023.json 제외\n",
    "#\n",
    "# base_path = \"D:/Dog/noseprints/data\" # base_path를 현재 작업물이 있는 폴더로 지정\n",
    "#\n",
    "# for i in json_range:\n",
    "#     input_file = os.path.join(base_path, f\"a{i:03d}.json\")\n",
    "#\n",
    "#     # JSON 파일 읽기\n",
    "#     with open(input_file, 'r', encoding='utf-8') as file:\n",
    "#         data = json.load(file)\n",
    "#\n",
    "#     # \"file_name\" 필드 수정\n",
    "#     for image in data[\"images\"]:\n",
    "#         image_id = image[\"id\"]\n",
    "#         new_file_name = f\"a{i:03d}_{image_id}.jpg\"\n",
    "#         image[\"file_name\"] = new_file_name\n",
    "#\n",
    "#     # 변경된 내용을 파일에 다시 저장\n",
    "#     output_file = input_file\n",
    "#     with open(output_file, 'w', encoding='utf-8') as file:\n",
    "#         json.dump(data, file, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import json\n",
    "# merged_data = []\n",
    "#\n",
    "# # 각 json 파일을 읽고 병합\n",
    "# for json_file in json_files:\n",
    "#     with open(json_file, 'r', encoding='utf-8') as file:\n",
    "#         data = json.load(file)\n",
    "#         merged_data.append(data)\n",
    "#\n",
    "# output_path = \"D:\\\\Dog\\\\noseprints\\\\data\"\n",
    "# os.makedirs(output_path, exist_ok=True)\n",
    "#\n",
    "# # 병합된 데이터를 D:\\Dog\\noseprints\\data\\labels\\label.json 파일에 저장\n",
    "# output_file = os.path.join(output_path, \"label.json\")\n",
    "# with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "#     json.dump(merged_data, outfile, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python example.py --datasets COCO --img_path ../noseprints/data/images/a024  --label ../noseprints/data/a024.json --convert_output_path ../noseprints/data/labels --img_type '.jpg' --manifest_path ./ --cls_list_file ../noseprints/class.names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # json 파일을 YOLO 포맷으로 변환\n",
    "# import subprocess\n",
    "#\n",
    "# def run_command(img_path, label_path):\n",
    "#     command = f\"python D:/Dog/convert2Yolo/example.py --datasets COCO --img_path {img_path} --label {label_path} --convert_output_path D:/Dog/noseprints/data/labels --img_type '.jpg' --manifest_path D:/Dog --cls_list_file D:/Dog/noseprints/class.names\"\n",
    "#\n",
    "#     result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, text=True)\n",
    "#\n",
    "#     print(result.stdout)\n",
    "#     print(result.stderr)\n",
    "#\n",
    "# # 각 경로에 대한 루프를 실행\n",
    "# for i in range(1, 25):\n",
    "#     if i in [21, 23]:\n",
    "#         continue\n",
    "#     img_path = f\"D:/Dog/noseprints/data/images/a0{i}\"\n",
    "#     label_path = f\"D:/Dog/noseprints/data/a0{i}.json\"\n",
    "#     run_command(img_path, label_path)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 이미지를 train 데이터셋과 test 데이터셋으로 구분\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(glob.glob(\"D:/Dog/noseprints/data/images/*.jpg\")) # 이미지 데이터\n",
    "y= np.array(glob.glob(\"D:/Dog/noseprints/data/labels/*.txt\")) # 라벨 데이터\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n",
    "# stratify 사용 시 이미지 갯수가 너무 적으면 아예 분리가 안됨"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 이미지 파일과 라벨 파일을 정렬하고, 파일 이름을 기준으로 데이터셋을 분할\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def extract_filename(file_path):\n",
    "    return os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "image_files = np.array(sorted(glob.glob(\"D:/Dog/noseprints/data/images/*.jpg\")))\n",
    "label_files = np.array(sorted(glob.glob(\"D:/Dog/noseprints/data/labels/*.txt\")))\n",
    "\n",
    "image_filenames = np.array([extract_filename(f) for f in image_files])\n",
    "label_filenames = np.array([extract_filename(f) for f in label_files])\n",
    "\n",
    "assert np.array_equal(image_filenames, label_filenames), \"이미지와 라벨 파일이 일치하지 않음.\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_files, label_files, test_size=0.1, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train 데이터셋과 test 데이터셋을 각각 train, test 폴더에 복사\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def copy_files_to_folder(file_list, destination_folder):\n",
    "    for file in file_list:\n",
    "        shutil.copy(file, destination_folder)\n",
    "\n",
    "# Train 데이터셋과 Test 데이터셋을 각각 train, test 폴더에 복사\n",
    "train_image_folder = 'D:/Dog/noseprints/data/train/images/'\n",
    "train_label_folder = 'D:/Dog/noseprints/data/train/labels/'\n",
    "test_image_folder = 'D:/Dog/noseprints/data/test/images/'\n",
    "test_label_folder = 'D:/Dog/noseprints/data/test/labels/'\n",
    "\n",
    "# 폴더가 없는 경우 생성\n",
    "os.makedirs(train_image_folder, exist_ok=True)\n",
    "os.makedirs(train_label_folder, exist_ok=True)\n",
    "os.makedirs(test_image_folder, exist_ok=True)\n",
    "os.makedirs(test_label_folder, exist_ok=True)\n",
    "\n",
    "# 이미지 파일 복사\n",
    "copy_files_to_folder(X_train, train_image_folder)\n",
    "copy_files_to_folder(X_test, test_image_folder)\n",
    "\n",
    "# 라벨 파일 복사\n",
    "copy_files_to_folder(y_train, train_label_folder)\n",
    "copy_files_to_folder(y_test, test_label_folder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 이미지 resize 시 라벨링 데이터도 같이 수정해야 함..진행하지 않기로 결정"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# yaml 파일 경로 : D:/Dog/noseprints/dog.yaml\n",
    "# test data의 경우, 라벨링을 정보를 활용하지 않음\n",
    "import yaml"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# yaml 파일을 읽어서 데이터셋을 생성\n",
    "with open(\"D:/Dog/noseprints/dog.yaml\", 'r') as yaml_file:\n",
    "    data = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "    print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# yolov5로 경로이동\n",
    "cd ../yolov5\n",
    "\n",
    "# train\n",
    "'''\n",
    "python train.py \\\n",
    "--img 이미지 사이즈 \\\n",
    "--batch 배치 사이즈 \\\n",
    "--data custom.yaml 파일경로 \\\n",
    "--cfg 사용할 모델의 yaml 파일경로 \\\n",
    "--weights 학습에 사용할 모델 \\\n",
    "--name 학습된 정보를 runs 폴더 안에 저장할 이름 \\\n",
    "--project wanbd에 저장할 프로젝트명\n",
    "'''\n",
    "\n",
    "# # 여러 파라미터 중 핵심만 사용\n",
    "# python train.py \\\n",
    "# --data ../starbucks/custom.yaml \\\n",
    "# --weights yolov5m.pt\n",
    "#\n",
    "# # 조금 더 조절하고 싶은 경우\n",
    "# python train.py \\\n",
    "# --data ../starbucks/custom.yaml \\\n",
    "# --weights yolov5m.pt \\\n",
    "# --batch ?? \\\n",
    "# --epochs ??? \\\n",
    "# --name starbucks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# clear_session\n",
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 학습된 모델을 이용하여 train\n",
    "!python D:/Dog/yolov5/train.py --batch 8 --epochs 10 --data D:/Dog/dog.yaml --weights yolov5m.pt --name dog1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                  epoch        train/box_loss        train/obj_loss  \\\n0                     0              0.108170              0.030438   \n1                     1              0.094074              0.029610   \n2                     2              0.081843              0.028148   \n3                     3              0.078729              0.026634   \n4                     4              0.073708              0.026890   \n5                     5              0.068477              0.024417   \n6                     6              0.068019              0.024267   \n7                     7              0.064715              0.022515   \n8                     8              0.059321              0.023847   \n9                     9              0.052544              0.024765   \n\n         train/cls_loss     metrics/precision        metrics/recall  \\\n0              0.081701              0.000000               0.00000   \n1              0.077287              0.001049               0.19444   \n2              0.073499              0.002666               0.50000   \n3              0.071605              0.006348               0.61111   \n4              0.068633              0.020038               0.33333   \n5              0.066950              0.006280               0.69444   \n6              0.068923              0.008727               0.75000   \n7              0.068203              0.011284               0.91667   \n8              0.065046              0.009374               0.91667   \n9              0.065485              0.008812               0.91667   \n\n        metrics/mAP_0.5  metrics/mAP_0.5:0.95          val/box_loss  \\\n0              0.000000              0.000000              0.099950   \n1              0.017247              0.004573              0.079230   \n2              0.012080              0.004304              0.071837   \n3              0.032620              0.009898              0.064968   \n4              0.043943              0.016537              0.064030   \n5              0.022526              0.010168              0.058859   \n6              0.037050              0.012387              0.063993   \n7              0.127930              0.042809              0.061326   \n8              0.105400              0.049029              0.050328   \n9              0.188170              0.103060              0.045527   \n\n           val/obj_loss          val/cls_loss                 x/lr0  \\\n0              0.023176              0.076658              0.088300   \n1              0.022076              0.076168              0.075433   \n2              0.020123              0.077275              0.062288   \n3              0.018708              0.077026              0.048867   \n4              0.017530              0.076516              0.035168   \n5              0.016464              0.074885              0.021192   \n6              0.015791              0.074476              0.006938   \n7              0.015446              0.073747              0.003070   \n8              0.015684              0.071900              0.003070   \n9              0.015538              0.071760              0.002080   \n\n                  x/lr1                 x/lr2  \n0              0.001300              0.001300  \n1              0.002433              0.002433  \n2              0.003288              0.003288  \n3              0.003867              0.003867  \n4              0.004168              0.004168  \n5              0.004191              0.004191  \n6              0.003938              0.003938  \n7              0.003070              0.003070  \n8              0.003070              0.003070  \n9              0.002080              0.002080  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoch</th>\n      <th>train/box_loss</th>\n      <th>train/obj_loss</th>\n      <th>train/cls_loss</th>\n      <th>metrics/precision</th>\n      <th>metrics/recall</th>\n      <th>metrics/mAP_0.5</th>\n      <th>metrics/mAP_0.5:0.95</th>\n      <th>val/box_loss</th>\n      <th>val/obj_loss</th>\n      <th>val/cls_loss</th>\n      <th>x/lr0</th>\n      <th>x/lr1</th>\n      <th>x/lr2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.108170</td>\n      <td>0.030438</td>\n      <td>0.081701</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.099950</td>\n      <td>0.023176</td>\n      <td>0.076658</td>\n      <td>0.088300</td>\n      <td>0.001300</td>\n      <td>0.001300</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.094074</td>\n      <td>0.029610</td>\n      <td>0.077287</td>\n      <td>0.001049</td>\n      <td>0.19444</td>\n      <td>0.017247</td>\n      <td>0.004573</td>\n      <td>0.079230</td>\n      <td>0.022076</td>\n      <td>0.076168</td>\n      <td>0.075433</td>\n      <td>0.002433</td>\n      <td>0.002433</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.081843</td>\n      <td>0.028148</td>\n      <td>0.073499</td>\n      <td>0.002666</td>\n      <td>0.50000</td>\n      <td>0.012080</td>\n      <td>0.004304</td>\n      <td>0.071837</td>\n      <td>0.020123</td>\n      <td>0.077275</td>\n      <td>0.062288</td>\n      <td>0.003288</td>\n      <td>0.003288</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.078729</td>\n      <td>0.026634</td>\n      <td>0.071605</td>\n      <td>0.006348</td>\n      <td>0.61111</td>\n      <td>0.032620</td>\n      <td>0.009898</td>\n      <td>0.064968</td>\n      <td>0.018708</td>\n      <td>0.077026</td>\n      <td>0.048867</td>\n      <td>0.003867</td>\n      <td>0.003867</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.073708</td>\n      <td>0.026890</td>\n      <td>0.068633</td>\n      <td>0.020038</td>\n      <td>0.33333</td>\n      <td>0.043943</td>\n      <td>0.016537</td>\n      <td>0.064030</td>\n      <td>0.017530</td>\n      <td>0.076516</td>\n      <td>0.035168</td>\n      <td>0.004168</td>\n      <td>0.004168</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>0.068477</td>\n      <td>0.024417</td>\n      <td>0.066950</td>\n      <td>0.006280</td>\n      <td>0.69444</td>\n      <td>0.022526</td>\n      <td>0.010168</td>\n      <td>0.058859</td>\n      <td>0.016464</td>\n      <td>0.074885</td>\n      <td>0.021192</td>\n      <td>0.004191</td>\n      <td>0.004191</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>0.068019</td>\n      <td>0.024267</td>\n      <td>0.068923</td>\n      <td>0.008727</td>\n      <td>0.75000</td>\n      <td>0.037050</td>\n      <td>0.012387</td>\n      <td>0.063993</td>\n      <td>0.015791</td>\n      <td>0.074476</td>\n      <td>0.006938</td>\n      <td>0.003938</td>\n      <td>0.003938</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>0.064715</td>\n      <td>0.022515</td>\n      <td>0.068203</td>\n      <td>0.011284</td>\n      <td>0.91667</td>\n      <td>0.127930</td>\n      <td>0.042809</td>\n      <td>0.061326</td>\n      <td>0.015446</td>\n      <td>0.073747</td>\n      <td>0.003070</td>\n      <td>0.003070</td>\n      <td>0.003070</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>0.059321</td>\n      <td>0.023847</td>\n      <td>0.065046</td>\n      <td>0.009374</td>\n      <td>0.91667</td>\n      <td>0.105400</td>\n      <td>0.049029</td>\n      <td>0.050328</td>\n      <td>0.015684</td>\n      <td>0.071900</td>\n      <td>0.003070</td>\n      <td>0.003070</td>\n      <td>0.003070</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>0.052544</td>\n      <td>0.024765</td>\n      <td>0.065485</td>\n      <td>0.008812</td>\n      <td>0.91667</td>\n      <td>0.188170</td>\n      <td>0.103060</td>\n      <td>0.045527</td>\n      <td>0.015538</td>\n      <td>0.071760</td>\n      <td>0.002080</td>\n      <td>0.002080</td>\n      <td>0.002080</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 결과 확인\n",
    "path = 'D:/Dog/yolov5/runs/train/dog12/results.csv'\n",
    "df = pd.read_csv(path)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T18:21:34.735196200Z",
     "start_time": "2023-05-08T18:21:34.580187300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 학습된 모델을 이용해 test\n",
    "!python D:/Dog/yolov5/detect.py --weights D:/Dog/yolov5/runs/train/dog12/weights/best.pt --source D:/Dog/noseprints/data/test/images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# exp3 전부 no detection...데이터가 턱없이 모자르다는 것을 확인"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
